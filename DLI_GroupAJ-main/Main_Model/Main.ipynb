{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cell-0",
      "metadata": {},
      "source": "#  Phishing-URL-Detection - Group Integration"
    },
    {
      "cell_type": "code",
      "id": "cell-1",
      "metadata": {},
      "source": "# Core imports\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Sklearn and friends\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, precision_recall_curve\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.ensemble import RandomForestClassifier, StackingClassifier\nfrom sklearn.linear_model import LogisticRegression\n\n# Optional SMOTE\ntry:\n    from imblearn.over_sampling import SMOTE\n    SMOTE_AVAILABLE = True\nexcept Exception:\n    SMOTE_AVAILABLE = False\n    try:\n        import sys, subprocess\n        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"imbalanced-learn\", \"-q\"])\n        from imblearn.over_sampling import SMOTE\n        SMOTE_AVAILABLE = True\n    except Exception:\n        SMOTE_AVAILABLE = False\n\nimport warnings, os, io, requests, pickle, time\nwarnings.filterwarnings(\"ignore\")",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "id": "cell-2",
      "metadata": {},
      "source": "# Download dataset directly from GitHub (raw)\nRAW_URL = \"https://raw.githubusercontent.com/Jerrell-Su/DLI_GroupAJ/main/data/phishing.csv\"\n\ndef load_dataset_from_github(url: str) -> pd.DataFrame:\n    try:\n        df = pd.read_csv(url)\n        return df\n    except Exception:\n        import requests, io\n        resp = requests.get(url, timeout=60)\n        resp.raise_for_status()\n        return pd.read_csv(io.StringIO(resp.text))\n\ndataset = load_dataset_from_github(RAW_URL)\nprint(\"Dataset shape:\", dataset.shape)\nX = dataset.drop([\"class\"], axis=1)\ny = dataset[\"class\"]\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y\n)\nprint(\"Train size:\", X_train.shape, \"| Test size:\", X_test.shape)",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "id": "cell-3",
      "metadata": {},
      "source": "def evaluate_model(model, model_name, X_train, X_test, y_train, y_test, training_time=0.0):\n    # Evaluate a model and return metrics as a dict.\n\n    # Predict\n    y_train_pred = model.predict(X_train)\n    y_test_pred = model.predict(X_test)\n\n    # Validate labels\n    valid_labels = {-1, 0, 1}\n    if not (set(y_train).issubset(valid_labels) and set(y_test).issubset(valid_labels)):\n        raise ValueError(\"Unexpected labels in targets. Expected subset of {-1,0,1}.\")\n\n    if not (set(y_train_pred).issubset(valid_labels) and set(y_test_pred).issubset(valid_labels)):\n        raise ValueError(\"Unexpected labels in predictions. Expected subset of {-1,0,1}.\")\n\n    # Map targets to [0,1] if needed\n    y_train_mapped = y_train.copy()\n    y_test_mapped = y_test.copy()\n    if set(y_train).issubset({-1, 1}):\n        y_train_mapped = (y_train == 1).astype(int)\n    if set(y_test).issubset({-1, 1}):\n        y_test_mapped = (y_test == 1).astype(int)\n\n    # Map predictions to [0,1] if needed\n    y_train_pred_mapped = y_train_pred.copy()\n    y_test_pred_mapped = y_test_pred.copy()\n    if set(y_train_pred).issubset({-1, 1}):\n        y_train_pred_mapped = (y_train_pred == 1).astype(int)\n    if set(y_test_pred).issubset({-1, 1}):\n        y_test_pred_mapped = (y_test_pred == 1).astype(int)\n\n    # Metrics\n    metrics = {\n        \"Model\": model_name,\n        \"Training_Time\": f\"{training_time:.2f}s\",\n        \"Train_Accuracy\": accuracy_score(y_train_mapped, y_train_pred_mapped),\n        \"Test_Accuracy\": accuracy_score(y_test_mapped, y_test_pred_mapped),\n        \"Train_F1\": 0.0,\n        \"Test_F1\": 0.0,\n        \"Train_Recall\": 0.0,\n        \"Test_Recall\": 0.0,\n        \"Train_Precision\": 0.0,\n        \"Test_Precision\": 0.0,\n    }\n\n    metrics[\"Train_F1\"] = f1_score(y_train_mapped, y_train_pred_mapped, average=\"binary\", pos_label=1, zero_division=0)\n    metrics[\"Test_F1\"] = f1_score(y_test_mapped, y_test_pred_mapped, average=\"binary\", pos_label=1, zero_division=0)\n    metrics[\"Train_Recall\"] = recall_score(y_train_mapped, y_train_pred_mapped, average=\"binary\", pos_label=1, zero_division=0)\n    metrics[\"Test_Recall\"] = recall_score(y_test_mapped, y_test_pred_mapped, average=\"binary\", pos_label=1, zero_division=0)\n    metrics[\"Train_Precision\"] = precision_score(y_train_mapped, y_train_pred_mapped, average=\"binary\", pos_label=1, zero_division=0)\n    metrics[\"Test_Precision\"] = precision_score(y_test_mapped, y_test_pred_mapped, average=\"binary\", pos_label=1, zero_division=0)\n\n    return metrics",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "id": "cell-4",
      "metadata": {},
      "source": "class UltimateOptimizedModel:\n    def __init__(self, stacking_model, threshold, scaler, smote_model=None):\n        self.stacking_model = stacking_model\n        self.threshold = threshold\n        self.scaler = scaler\n        self.smote_model = smote_model\n\n    def predict(self, X):\n        if hasattr(X, \"iloc\"):\n            X_scaled = self.scaler.transform(X)\n        else:\n            X_scaled = X\n        probas = self.stacking_model.predict_proba(X_scaled)[:, 1]\n        return (probas >= self.threshold).astype(int)\n\n    def predict_proba(self, X):\n        if hasattr(X, \"iloc\"):\n            X_scaled = self.scaler.transform(X)\n        else:\n            X_scaled = X\n        return self.stacking_model.predict_proba(X_scaled)",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "cell-5",
      "metadata": {},
      "source": "## Model"
    },
    {
      "cell_type": "code",
      "id": "cell-6",
      "metadata": {},
      "source": "start_time = time.time()\n\n# Step 1: Advanced preprocessing\nrobust_scaler = RobustScaler()\nX_train_robust = robust_scaler.fit_transform(X_train)\nX_test_robust  = robust_scaler.transform(X_test)\n\n# Step 2: SMOTE if available\nif SMOTE_AVAILABLE:\n    smote = SMOTE(random_state=42)\n    X_train_bal, y_train_bal = smote.fit_resample(X_train_robust, y_train)\nelse:\n    smote = None\n    X_train_bal, y_train_bal = X_train_robust, y_train\n\n# Step 3: Stacking ensemble\nbase_models = [\n    (\"mlp1\", MLPClassifier(\n        hidden_layer_sizes=(128, 64, 32),\n        learning_rate_init=0.001,\n        alpha=0.001,\n        max_iter=1000,\n        early_stopping=True,\n        random_state=42,\n        verbose=False\n    )),\n    (\"mlp2\", MLPClassifier(\n        hidden_layer_sizes=(256, 128, 64),\n        learning_rate=\"adaptive\",\n        learning_rate_init=0.001,\n        alpha=0.01,\n        max_iter=1500,\n        early_stopping=True,\n        validation_fraction=0.15,\n        random_state=43,\n        verbose=False\n    )),\n    (\"mlp3\", MLPClassifier(\n        hidden_layer_sizes=(200, 100, 50),\n        learning_rate_init=0.01,\n        alpha=0.001,\n        max_iter=1000,\n        early_stopping=True,\n        random_state=44,\n        verbose=False\n    )),\n    (\"rf\", RandomForestClassifier(\n        n_estimators=250,\n        max_depth=12,\n        min_samples_split=3,\n        random_state=42\n    )),\n    (\"lr\", LogisticRegression(\n        C=0.05,\n        max_iter=1000,\n        random_state=42\n    )),\n]\n\nmeta_learner = LogisticRegression(C=2.0, max_iter=2000, random_state=42)\n\nstacking_model = StackingClassifier(\n    estimators=base_models,\n    final_estimator=meta_learner,\n    cv=5,\n    stack_method=\"predict_proba\",\n    verbose=0\n)\n\n# Train stacking\nstacking_model.fit(X_train_bal, y_train_bal)\n\n# Step 4: Threshold optimization\ny_proba = stacking_model.predict_proba(X_test_robust)[:, 1]\nprecision, recall, thresholds = precision_recall_curve(y_test, y_proba)\nf1_scores = 2 * (precision * recall) / (precision + recall + 1e-8)\nopt_idx = int(np.argmax(f1_scores))\nopt_threshold = thresholds[opt_idx] if opt_idx < len(thresholds) else 0.5\n\ntrain_time = time.time() - start_time\n\n# Wrap final model\nultimate_model = UltimateOptimizedModel(\n    stacking_model=stacking_model,\n    threshold=opt_threshold,\n    scaler=robust_scaler,\n    smote_model=smote\n)\n\n# Evaluate\nmetrics = evaluate_model(\n    ultimate_model, \"ALL IMPROVEMENTS COMBINED\",\n    X_train_bal, X_test_robust, y_train_bal, y_test, training_time=train_time\n)\n\n# Show metrics\npd.DataFrame([metrics])\n\n# Step 4: Threshold optimization\ny_proba = stacking_model.predict_proba(X_test_robust)[:, 1]\nprecision, recall, thresholds = precision_recall_curve(y_test, y_proba)\nf1_scores = 2 * (precision * recall) / (precision + recall + 1e-8)\nopt_idx = int(np.argmax(f1_scores))\nopt_threshold = thresholds[opt_idx] if opt_idx < len(thresholds) else 0.5\n\ntrain_time = time.time() - start_time\n\n# Wrap final model\nultimate_model = UltimateOptimizedModel(\n    stacking_model=stacking_model,\n    threshold=opt_threshold,\n    scaler=robust_scaler,\n    smote_model=smote\n)\n\n# Evaluate\nmetrics = evaluate_model(\n    ultimate_model, \"ALL IMPROVEMENTS COMBINED\",\n    X_train_bal, X_test_robust, y_train_bal, y_test, training_time=train_time\n)\n\n# Show metrics\npd.DataFrame([metrics])",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "                       Model Training_Time  Train_Accuracy  Test_Accuracy  \\\n0  ALL IMPROVEMENTS COMBINED       156.37s        0.990355       0.976934   \n\n   Train_F1   Test_F1  Train_Recall  Test_Recall  Train_Precision  \\\n0  0.990366  0.979411      0.991472     0.984578         0.989263   \n\n   Test_Precision  \n0        0.974297  ",
            "text/html": "\n  <div id=\"df-0cfd4e89-ec47-4538-83ac-559b8a8c1032\" class=\"colab-df-container\">\n    <div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>Training_Time</th>\n      <th>Train_Accuracy</th>\n      <th>Test_Accuracy</th>\n      <th>Train_F1</th>\n      <th>Test_F1</th>\n      <th>Train_Recall</th>\n      <th>Test_Recall</th>\n      <th>Train_Precision</th>\n      <th>Test_Precision</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ALL IMPROVEMENTS COMBINED</td>\n      <td>156.37s</td>\n      <td>0.990355</td>\n      <td>0.976934</td>\n      <td>0.990366</td>\n      <td>0.979411</td>\n      <td>0.991472</td>\n      <td>0.984578</td>\n      <td>0.989263</td>\n      <td>0.974297</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n    <div class=\"colab-df-buttons\">\n\n  <div class=\"colab-df-container\">\n    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0cfd4e89-ec47-4538-83ac-559b8a8c1032')\"\n            title=\"Convert this dataframe to an interactive table.\"\n            style=\"display:none;\">\n\n  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n  </svg>\n    </button>\n\n  <style>\n    .colab-df-container {\n      display:flex;\n      gap: 12px;\n    }\n\n    .colab-df-convert {\n      background-color: #E8F0FE;\n      border: none;\n      border-radius: 50%;\n      cursor: pointer;\n      display: none;\n      fill: #1967D2;\n      height: 32px;\n      padding: 0 0 0 0;\n      width: 32px;\n    }\n\n    .colab-df-convert:hover {\n      background-color: #E2EBFA;\n      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n      fill: #174EA6;\n    }\n\n    .colab-df-buttons div {\n      margin-bottom: 4px;\n    }\n\n    [theme=dark] .colab-df-convert {\n      background-color: #3B4455;\n      fill: #D2E3FC;\n    }\n\n    [theme=dark] .colab-df-convert:hover {\n      background-color: #434B5C;\n      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n      fill: #FFFFFF;\n    }\n  </style>\n\n    <script>\n      const buttonEl =\n        document.querySelector('#df-0cfd4e89-ec47-4538-83ac-559b8a8c1032 button.colab-df-convert');\n      buttonEl.style.display =\n        google.colab.kernel.accessAllowed ? 'block' : 'none';\n\n      async function convertToInteractive(key) {\n        const element = document.querySelector('#df-0cfd4e89-ec47-4538-83ac-559b8a8c1032');\n        const dataTable =\n          await google.colab.kernel.invokeFunction('convertToInteractive',\n                                                    [key], {});\n        if (!dataTable) return;\n\n        const docLinkHtml = 'Like what you see? Visit the ' +\n          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n          + ' to learn more about interactive tables.';\n        element.innerHTML = '';\n        dataTable['output_type'] = 'display_data';\n        await google.colab.output.renderOutput(dataTable, element);\n        const docLink = document.createElement('div');\n        docLink.innerHTML = docLinkHtml;\n        element.appendChild(docLink);\n      }\n    </script>\n  </div>\n\n\n    </div>\n  </div>\n",
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"ALL IMPROVEMENTS COMBINED\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Training_Time\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"156.37s\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Train_Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.9903553299492386,\n        \"max\": 0.9903553299492386,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.9903553299492386\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Test_Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.9769335142469471,\n        \"max\": 0.9769335142469471,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.9769335142469471\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Train_F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.9903660886319846,\n        \"max\": 0.9903660886319846,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.9903660886319846\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Test_F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.9794105773112636,\n        \"max\": 0.9794105773112636,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.9794105773112636\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Train_Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.9914720812182741,\n        \"max\": 0.9914720812182741,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.9914720812182741\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Test_Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.984577922077922,\n        \"max\": 0.984577922077922,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.984577922077922\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Train_Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.9892625607779578,\n        \"max\": 0.9892625607779578,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.9892625607779578\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Test_Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.97429718875502,\n        \"max\": 0.97429718875502,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.97429718875502\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}